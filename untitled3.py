# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J3M2XbsbGmOReRKKgv-TFiv4XZt3Ivk4
"""

# Full pipeline: synthetic data -> features -> LSTM+Attention & Transformer -> LightGBM residual -> ensemble
# Designed for Colab / local run. TensorFlow 2.x assumed.

import os
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error
import tensorflow as tf

# -------------------------
# 1) Reproducibility seeds
# -------------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)
os.environ['PYTHONHASHSEED'] = str(SEED)

# -------------------------
# 2) Generate synthetic data
# -------------------------
def generate_synthetic_data(n_samples=3000, noise_scale=0.08):
    t = np.arange(n_samples)
    f1 = 0.6*np.sin(0.02*t) + 0.12*np.sin(0.005*t*3) + noise_scale*np.random.randn(n_samples)
    f2 = 0.4*np.sin(0.04*t + 1.2) + 0.08*np.random.randn(n_samples)
    f3 = 0.3*np.cos(0.03*t + 2.0) + 0.06*np.random.randn(n_samples)
    f4 = 0.1*np.random.randn(n_samples)  # noise-ish
    f5 = 0.8*np.sin(0.01*t + 0.5) + 0.05*np.random.randn(n_samples)

    # non-stationary trend + regime change
    trend = 0.0005*t + 0.3*(t>int(n_samples*0.6))(0.0008(t-int(n_samples*0.6)))

    target = (0.45*f1 + 0.2*f2 + 0.25*f3 + 0.05*f4 +
              0.3*np.sin(0.015*t) + trend + 0.08*np.random.randn(n_samples))

    df = pd.DataFrame({
        'f1': f1, 'f2': f2, 'f3': f3, 'f4': f4, 'f5': f5,
        'target': target,
        'time': pd.date_range('2000-01-01', periods=n_samples, freq='H')
    })
    return df

df = generate_synthetic_data(n_samples=3000)
print("Generated df shape:", df.shape)
df.head()

# -------------------------
# 3) Feature engineering
# -------------------------
def add_time_features(dframe):
    dframe['hour'] = dframe['time'].dt.hour
    dframe['dayofweek'] = dframe['time'].dt.dayofweek
    return dframe

def add_rolling_features(dframe, windows=(3, 6, 24)):
    for w in windows:
        dframe[f'target_roll_mean_{w}'] = dframe['target'].rolling(w, min_periods=1).mean()
        dframe[f'target_roll_std_{w}']  = dframe['target'].rolling(w, min_periods=1).std().fillna(0)
    return dframe

def add_lag_features(dframe, lags=(1,2,3,24)):
    for lag in lags:
        dframe[f'target_lag_{lag}'] = dframe['target'].shift(lag)
    dframe.fillna(method='bfill', inplace=True)
    return dframe

df = add_time_features(df)
df = add_rolling_features(df, windows=(3,6,24))
df = add_lag_features(df, lags=(1,2,3,24))

# Drop time column for model inputs but keep for plotting
times = df['time'].copy()
df_model = df.drop(columns=['time'])

print("After features:", df_model.columns.tolist())

# -------------------------
# 4) Scaling
# -------------------------
scaler = StandardScaler()
scaled = scaler.fit_transform(df_model)
scaled_df = pd.DataFrame(scaled, columns=df_model.columns)

# -------------------------
# 5) Windowing function
# -------------------------
def create_windows(data_arr, seq_len=48, target_col_index=None, step=1):
    X, y, idxs = [], [], []
    n = len(data_arr)
    if target_col_index is None:
        target_col_index = data_arr.shape[1]-1
    for start in range(0, n - seq_len, step):
        end = start + seq_len
        X.append(data_arr[start:end, :-1])    # all features except target
        y.append(data_arr[end, target_col_index])
        idxs.append(end)
    return np.array(X), np.array(y), np.array(idxs)

SEQ_LEN = 48  # 48-hour window
X, y, idxs = create_windows(scaled_df.values, seq_len=SEQ_LEN, target_col_index=scaled_df.columns.get_loc('target'))

print("X shape:", X.shape, "y shape:", y.shape)

# -------------------------
# 6) Helper metrics & plotting
# -------------------------
def rmse(a,b): return np.sqrt(mean_squared_error(a,b))
def mape(a,b): return np.mean(np.abs((a-b)/(np.clip(np.abs(a),1e-8,None))))*100

def evaluate(y_true, y_pred, prefix=""):
    r = rmse(y_true, y_pred)
    m = mean_absolute_error(y_true, y_pred)
    mp = mape(y_true, y_pred)
    print(f"{prefix} RMSE: {r:.6f}  MAE: {m:.6f}  MAPE: {mp:.4f}%")
    return r,m,mp

# -------------------------
# 7) Models: Attention layer, LSTM model, Transformer encoder
# -------------------------
from tensorflow.keras import layers, Model, Input

class AttentionLayer(layers.Layer):
    def _init_(self, units=None, **kwargs):
        super()._init_(**kwargs)
        self.units = units

    def build(self, input_shape):
        dim = int(input_shape[-1])
        self.W = self.add_weight(shape=(dim, dim), initializer='glorot_uniform', trainable=True, name='W_att')
        self.b = self.add_weight(shape=(dim,), initializer='zeros', trainable=True, name='b_att')
        self.v = self.add_weight(shape=(dim,1), initializer='glorot_uniform', trainable=True, name='v_att')
        super().build(input_shape)

    def call(self, inputs, mask=None):
        # inputs: (batch, time, features)
        score = tf.nn.tanh(tf.tensordot(inputs, self.W, axes=[[2],[0]]) + self.b)
        score = tf.tensordot(score, self.v, axes=[[2],[0]])  # (batch, time, 1)
        attention_weights = tf.nn.softmax(score, axis=1)  # (batch, time, 1)
        context = tf.reduce_sum(attention_weights * inputs, axis=1)  # (batch, features)
        return context, tf.squeeze(attention_weights, -1)

def build_lstm_attention(seq_len, n_features, lstm_units=64, dropout=0.2):
    inp = Input(shape=(seq_len, n_features))
    x = layers.Bidirectional(layers.LSTM(lstm_units, return_sequences=True))(inp)
    x = layers.Dropout(dropout)(x)
    context, att = AttentionLayer()(x)
    out = layers.Dense(1)(context)
    model = Model(inp, out)
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

# Transformer encoder block
def transformer_encoder_block(seq_len, n_features, head_size=64, num_heads=4, ff_dim=128, dropout=0.2):
    inp = Input(shape=(seq_len, n_features))
    x = inp
    x = layers.LayerNormalization(epsilon=1e-6)(x)
    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)
    x = layers.Dropout(dropout)(x)
    x = layers.Add()([x, inp])
    x2 = layers.LayerNormalization(epsilon=1e-6)(x)
    x2 = layers.Dense(ff_dim, activation='relu')(x2)
    x2 = layers.Dense(n_features)(x2)
    x = layers.Add()([x, x2])
    x = layers.GlobalAveragePooling1D()(x)
    out = layers.Dense(1)(x)
    model = Model(inp, out)
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

# -------------------------
# 8) TimeSeries CV (walk-forward) + training
# -------------------------
n_splits = 4
tscv = TimeSeriesSplit(n_splits=n_splits)
fold = 0

# Hold lists to collect final test predictions & metrics from each fold
fold_results = []

# We'll train on train_idx, validate on val_idx, then evaluate on next held-out test part (last split)
for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):
    print("\n" + "="*40)
    print(f"Fold {fold+1}/{n_splits}")
    X_tr, X_val = X[train_idx], X[val_idx]
    y_tr, y_val = y[train_idx], y[val_idx]

    n_features = X.shape[2]
    # Build models
    lstm_model = build_lstm_attention(SEQ_LEN, n_features, lstm_units=64, dropout=0.2)
    transformer_model = transformer_encoder_block(SEQ_LEN, n_features, head_size=32, num_heads=2, ff_dim=128, dropout=0.2)

    callbacks = [
        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1),
        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6, verbose=1)
    ]

    print("Training LSTM+Attention ...")
    lstm_model.fit(X_tr, y_tr, validation_data=(X_val, y_val),
                   epochs=60, batch_size=64, callbacks=callbacks, verbose=1)

    print("Training Transformer ...")
    transformer_model.fit(X_tr, y_tr, validation_data=(X_val, y_val),
                          epochs=60, batch_size=64, callbacks=callbacks, verbose=1)

    # Evaluate on the next chunk after val if available; otherwise evaluate on val
    # Compute a simple test index range: take the next 10% or val slice as test
    test_start = val_idx[-1] + 1
    test_end = min(test_start + len(val_idx), len(X)-1)
    if test_start < test_end and test_start < len(X):
        X_test = X[test_start:test_end]
        y_test = y[test_start:test_end]
    else:
        # fallback: use val as test
        X_test, y_test = X_val, y_val

    print("Predicting on test segment ...")
    pred_lstm = lstm_model.predict(X_test).flatten()
    pred_trans = transformer_model.predict(X_test).flatten()

    # LightGBM residual modeling: train on train set residuals vs engineered flattened features
    # Build flattened features for LightGBM: last row of the window + simple aggregates
    def flatten_for_gbm(X_windows):
        # Return shape (n_samples, features_flat)
        flat = []
        for w in X_windows:
            last = w[-1]                # last timestep features
            mean = w.mean(axis=0)
            std = w.std(axis=0)
            flat.append(np.concatenate([last, mean, std]))
        return np.array(flat)

    try:
        import lightgbm as lgb
    except Exception as e:
        raise ImportError("Install lightgbm to run residual model: pip install lightgbm") from e

    X_tr_gbm = flatten_for_gbm(X_tr)
    X_val_gbm = flatten_for_gbm(X_val)
    X_test_gbm = flatten_for_gbm(X_test)

    # Train base NN (we'll use lstm predictions on train to compute residual)
    pred_tr_lstm = lstm_model.predict(X_tr).flatten()
    residual_tr = y_tr - pred_tr_lstm

    lgb_train = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.05, random_state=SEED)
    lgb_train.fit(X_tr_gbm, residual_tr, eval_set=[(X_val_gbm, y_val - lstm_model.predict(X_val).flatten())],
                  early_stopping_rounds=50, verbose=False)

    resid_pred_test = lgb_train.predict(X_test_gbm)
    final_pred = 0.5*pred_lstm + 0.5*pred_trans + resid_pred_test  # weighted ensemble + residual correction

    # Evaluate
    r_lstm = evaluate(y_test, pred_lstm, prefix="LSTM")
    r_trans = evaluate(y_test, pred_trans, prefix="Transformer")
    r_ens = evaluate(y_test, final_pred, prefix="Ensemble+Residual")

    fold_results.append({
        'fold': fold,
        'y_true': y_test,
        'pred_lstm': pred_lstm,
        'pred_trans': pred_trans,
        'pred_ensemble': final_pred,
        'metrics': {'lstm': r_lstm, 'trans': r_trans, 'ensemble': r_ens},
        'idxs': idxs[test_start:test_start+len(y_test)]
    })

# -------------------------
# 9) Aggregate results: plot last fold predictions vs true (de-scaled)
# -------------------------
# We'll inverse-transform predictions to original scale using the scaler.
# Because scaler was fit on all features, to invert target we need to reconstruct full feature vector
def inv_scale_target(scaled_targets):
    # scaled_targets: array shape (n,)
    # To invert, create dummy rows filled with zeros except target column set to scaled value,
    # then apply inverse_transform using scaler.
    inv = []
    zero_row = np.zeros((1, scaled_df.shape[1]))
    target_col = scaled_df.columns.get_loc('target')
    for val in scaled_targets:
        row = zero_row.copy()
        row[0, target_col] = val
        inv_row = scaler.inverse_transform(row)[0, target_col]
        inv.append(inv_row)
    return np.array(inv)

# plot for last fold
res = fold_results[-1]
y_true_orig = inv_scale_target(res['y_true'])
pred_ens_orig = inv_scale_target(res['pred_ensemble'])
pred_lstm_orig = inv_scale_target(res['pred_lstm'])
pred_trans_orig = inv_scale_target(res['pred_trans'])

plt.figure(figsize=(14,5))
plt.plot(y_true_orig, label='True', linewidth=1)
plt.plot(pred_lstm_orig, label='LSTM', alpha=0.8)
plt.plot(pred_trans_orig, label='Transformer', alpha=0.8)
plt.plot(pred_ens_orig, label='Ensemble+Residual', alpha=0.9)
plt.legend()
plt.title("Last fold: true vs preds (de-scaled)")
plt.show()

# Print summarized fold metrics
for fr in fold_results:
    m = fr['metrics']['ensemble']
    print(f"Fold {fr['fold']} ensemble RMSE {m[0]:.6f}, MAE {m[1]:.6f}, MAPE {m[2]:.4f}%")

print("\nPipeline finished. Save models if you want and iterate on hyperparams / features.")